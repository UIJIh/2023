{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a388076-b924-436b-964d-61dc3de2e6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files removed: 4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip cache purge  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "998ed4f1-240d-4acb-99db-90e4b043452f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting filelock (from torch)\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/5e/5d/97afbafd9d584ff1b45fcb354a479a3609bd97f912f8f1f6c563cb1fae21/filelock-3.12.4-py3-none-any.whl.metadata\n",
      "  Downloading filelock-3.12.4-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.11/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch)\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch)\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch)\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch)\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch)\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch)\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch)\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.0.0 (from torch)\n",
      "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (68.2.2)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.41.2)\n",
      "Collecting cmake (from triton==2.0.0->torch)\n",
      "  Obtaining dependency information for cmake from https://files.pythonhosted.org/packages/de/94/cba4b3ddc0d4555967cce8fd6e9fbced98a6bf62857db71c2400a7b6e183/cmake-3.27.5-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading cmake-3.27.5-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting lit (from triton==2.0.0->torch)\n",
      "  Downloading lit-16.0.6.tar.gz (153 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.7/153.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading filelock-3.12.4-py3-none-any.whl (11 kB)\n",
      "Downloading cmake-3.27.5-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.1/26.1 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: lit\n",
      "  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-16.0.6-py3-none-any.whl size=93584 sha256=6861ed9ed1ee5b9cbac12452309a13c0369810eadf71a9a745b3592f15943258\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/ab/84/e4/5af8c76af9e5bee472e825f1451c18bb3b261d80a7b3ec7f8a\n",
      "Successfully built lit\n",
      "Installing collected packages: lit, cmake, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, filelock, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
      "Successfully installed cmake-3.27.5 filelock-3.12.4 lit-16.0.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 triton-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1e4fe13-5849-4746-9d4d-f69a3a1af525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5b9f7a-9ae9-4d63-8fce-d851f8c242e4",
   "metadata": {},
   "source": [
    "# 1d array with numpy\n",
    "# 2d array(matix) with numpy\n",
    "# 1d array with pytorch tensor\n",
    "# 2d array with pytorch tensor  \n",
    " ### : shape, sizeof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e3376b6-c55b-4cac-a5db-df73ed9cd94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7eb39008-812d-4d4e-8a9e-17ad39947d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(t.dim())\n",
    "print(t.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ee43e2a-40da-4070-ac2d-f82f3f60a39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 6., 9.])\n"
     ]
    }
   ],
   "source": [
    "print(t[:, 2]) # 모든 row들 중에 (2 + 1)번째 col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbc71b59-9c33-4363-8f2d-402a741796ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.)\n"
     ]
    }
   ],
   "source": [
    "print(t[1, 2])  # (1 + 1)번째 row 중에 (2 + 1) 번째 col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11255d28-f102-4657-903c-faa001317c6f",
   "metadata": {},
   "source": [
    "# BroadCasting\n",
    ": 행렬 곱/합 rule에 맞지 않아도 auto casting해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72920612-633f-4fa5-8c87-b89a0fe6057b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "# vector + scalar\n",
    "m1 = torch.FloatTensor([[1, 1]])\n",
    "m2 = torch.FloatTensor([2])    # (1차원) [2] -> [[2, 2]]\n",
    "print(m1 + m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "100e1b9f-b9e2-4869-8fb8-0c73edaa7f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 5.],\n",
      "        [6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# (2x1) + (1x2) \n",
    "m3 = torch.FloatTensor([[2, 2]])  # -> (2, 2)\n",
    "m4 = torch.FloatTensor([[3], [4]]) # -> (2, 2)   \n",
    "print(m3 + m4)   # (2, 2) + (2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e74926-6f25-43d3-bc45-5aa30b2323b0",
   "metadata": {},
   "source": [
    "# Multiplication vs Matrix Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57524d3-04f8-46b7-bc43-bbdbf927cec1",
   "metadata": {},
   "source": [
    "### BroadCasting : element-wise-multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa0796c3-a4da-4535-9eb5-edaced50c162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6., 6.],\n",
      "        [8., 8.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (1x2) * (2x1)\n",
    "m5 = torch.FloatTensor([[2, 2]])  # 1x2\n",
    "m6 = torch.FloatTensor([[3], [4]])  # 2x1\n",
    "print(m5 * m6, '\\n')  # 원래는 (1, 1) - 행렬곱에서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04ef0d16-05a6-497a-8fe1-c04b84b54c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 4.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (2x1) * (1x2)\n",
    "print(m5 * m4, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642688cd-bf78-40a7-baa5-300642596a1c",
   "metadata": {},
   "source": [
    "### Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bff6778-5519-46ac-8636-562f3dfcb1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[14.]]) \n",
      "\n",
      "tensor([[6., 6.],\n",
      "        [8., 8.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(m5.matmul(m6), '\\n') \n",
    "print(m6.matmul(m5), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec817f8-3d76-4a77-ad1f-ab248351fe25",
   "metadata": {},
   "source": [
    "# Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ae7ed16-8662-4112-ace3-c2152a48dcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5000)\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([1,2])  # 1차원 (괄호 하나)\n",
    "print(t.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "114ad42f-1576-4244-b0fa-2f8f010fd3d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
     ]
    }
   ],
   "source": [
    "t = torch.LongTensor([1,2])\n",
    "print(t.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb945623-64e4-4122-9c31-9860e76a526c",
   "metadata": {},
   "source": [
    "이 오류는 PyTorch에서 `mean()` 함수를 호출할 때 발생한 것으로, 오류 메시지에서 알 수 있듯이 `mean()` 함수는 부동 소수점 또는 복소수 데이터 타입에 대해서만 동작합니다. 따라서 `torch.LongTensor`와 같은 **정수 데이터 타입** 에 대해서는 `mean()` 함수를 직접 호출할 수 없습니다.\n",
    "\n",
    "해결 방법 중 하나는 입력 Tensor를 부동 소수점 데이터 타입으로 변환한 후 `mean()` 함수를 호출하는 것입니다. 예를 들어 `torch.FloatTensor`로 변환한 후 `mean()`을 호출할 수 있습니다:\n",
    "\n",
    "```python\n",
    "t = torch.LongTensor([1, 2]).float()  # 정수 Tensor를 부동 소수점 Tensor로 변환\n",
    "print(t.mean())\n",
    "```\n",
    "\n",
    "또는 생성 시에 바로 부동 소수점 데이터 타입을 사용하도록 Tensor를 생성할 수도 있습니다:\n",
    "\n",
    "```python\n",
    "t = torch.FloatTensor([1, 2])\n",
    "print(t.mean())\n",
    "```\n",
    "\n",
    "이렇게 하면 오류가 발생하지 않고 Tensor의 평균을 계산할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b33da3a-24a0-4a74-bea7-c36c4410f2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5000)\n"
     ]
    }
   ],
   "source": [
    "m = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "print(m.mean())  # 4개 elemens의 mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "064dd78b-3e04-44b1-b5c5-cb50fecd9098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 3.])\n",
      "tensor([1.5000, 3.5000])\n",
      "tensor([1.5000, 3.5000])\n"
     ]
    }
   ],
   "source": [
    "print(m.mean(dim=0))  # 각 col(첫번째차원) 에 대한 평균\n",
    "print(m.mean(dim=1))  # 각 row(두번째차원) 에 대한 평균\n",
    "print(m.mean(dim=-1))  # 마찬가지로 row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33e7bb2-8375-4bbb-bffa-a6316c58809d",
   "metadata": {},
   "source": [
    "# Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e4913af8-63b7-47e2-bfaf-1af9302c84e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.)\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1, 4], [2, 3]])\n",
    "print(t.sum())  # 전체 elements 합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc7f79f5-827f-4e47-ab9c-11cbd64023c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 7.])\n",
      "tensor([5., 5.])\n",
      "tensor([5., 5.])\n"
     ]
    }
   ],
   "source": [
    "print(t.sum(dim=0))\n",
    "print(t.sum(dim=1))\n",
    "print(t.sum(dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f7aa6c-974d-44bf-877b-5c92e9050dfb",
   "metadata": {},
   "source": [
    "# Max and Argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1ee021b1-80f9-4ea5-a101-4190ed939c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n"
     ]
    }
   ],
   "source": [
    "print(t.max())  # return nur eins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a567d17-932c-4670-b9d7-6253c6d14dbd",
   "metadata": {},
   "source": [
    "### 그런데 dim을 specify하면 2 values도 return 가능함\n",
    "#### max 값 & argmax(=index) 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "709e2c9e-607b-40fb-b0f0-d409dd58d9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([2., 4.]),\n",
      "indices=tensor([1, 0]))\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1, 4], [2, 3]])\n",
    "print(t.max(dim=0))  # col 기준"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "207784c4-5f55-4195-8619-781ed340a857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 4.])\n",
      "tensor([1, 0])\n"
     ]
    }
   ],
   "source": [
    "print(t.max(dim=0)[0])  // 위 결과값(t.max(dim=0))은 배열\n",
    "                        // t.max(dim=0)[0]은 value\n",
    "print(t.max(dim=0)[1])  // t.max(dim=0)[1]은 index, argmax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
