{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9c58845",
   "metadata": {},
   "source": [
    "## 테스트 데이터셋의 네 개 리뷰 중 어떤 것이 실제 인간에 의해 작성된 것인지 정확하게 예측\n",
    "## 테스트 데이터셋의 'label' 필드를 복구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f43e59c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf63c23",
   "metadata": {},
   "source": [
    "# - seed : 동일한 시드 값을 사용하면 항상 동일한 난수 시퀀스가 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60972574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)  # 이 부분이 pandas의 sample 함수에도 영향을 줍니다.\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b844e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>sentence3</th>\n",
       "      <th>sentence4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_000</td>\n",
       "      <td>직원들 마음에 들지 않는다는 것은 알겠지만, 가지 말아야 할까? 인터넷에서 싸게 살...</td>\n",
       "      <td>직원들 진짜 싸가지 없어요 ㅋㅋㅋㅋ 가지 마숑  인터넷이 더 싼거 알면서도 이것저것...</td>\n",
       "      <td>직원들 정말 싸가지 없네요 ㅋㅋㅋㅋ 인터넷에서 더 싸게 구입할 수 있다는 걸 알면서...</td>\n",
       "      <td>직원들의 태도가 정말 별로였어요 ㅋㅋㅋㅋ 가볼만한 가게라는 소문을 듣고 인터넷으로 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_001</td>\n",
       "      <td>분위기 최고! 2층 창문이 넓어서 공기가 통하는 느낌이에요. 조명도 멋지고 음료와 ...</td>\n",
       "      <td>분위기가 너무 좋아요! 2층 창문이 넓어서 쾌적한 느낌이에요. 조명도 아름답고 음료...</td>\n",
       "      <td>분위기가 짱!! 2층 창문이 커서 탁 트여있는 느낌이에요 ㅎㅎ 조명도 예쁘고 음료랑...</td>\n",
       "      <td>분위기가 너무 좋아요! 2층 창문이 크고 넓어서 탁 트여있는 느낌이에요. 조명도 예...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_002</td>\n",
       "      <td>일단, 장사가 잘 되길 바라는 마음에서 별 다섯 개 드립니다. 간도 딱 맞았고, 저...</td>\n",
       "      <td>일단 장사가 잘되길 바라는 마음에서 별5개 드립니다 간도 맞았고 매운걸 좋아하는 입...</td>\n",
       "      <td>일단 저는 장사가 잘되기를 바라는 마음에서 별 다섯 개를 주고 싶어요. 맛도 딱 맞...</td>\n",
       "      <td>먼저, 칭찬과 응원의 의미로 별 다섯 개를 주고 싶습니다. 간도 딱 맞고, 저는 매...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_003</td>\n",
       "      <td>1편의 독특함 때문에 살짝 뒤로 밀린 느낌이 있지만, 여전히 재미있어요. 게임 시스...</td>\n",
       "      <td>1편의 신선함에 비해 약간 빛이 바래 보이지만, 여전히 재미있게 즐길 수 있어요. ...</td>\n",
       "      <td>1편의 독특함 때문에 약간의 비교가 불가피하지만, 이 게임은 여전히 흥미로워요. 시...</td>\n",
       "      <td>1편이 워낙 참신했던 탓에 좀 묻힌 감이 있긴 하지만 재미는 여전합니다. 시스템도 ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_004</td>\n",
       "      <td>빵점 주고 싶은걸 간신히 참았다...이런건 사상 유래가 없는,조지 루카스 영감의 스...</td>\n",
       "      <td>빵점을 주고 싶지만 참아냈습니다... 이 영화는 사상 유래가 없는 것 같아요. 조지...</td>\n",
       "      <td>빵점 주고 싶을 정도로 엄청 실망했어요... 이 영화는 별들의 전쟁처럼 역사적인 작...</td>\n",
       "      <td>빵점을 주고 싶었는데 참았어요... 이런 영화는 전례가 없는데, 조지 루카스의 스타...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                          sentence1  \\\n",
       "0  TRAIN_000  직원들 마음에 들지 않는다는 것은 알겠지만, 가지 말아야 할까? 인터넷에서 싸게 살...   \n",
       "1  TRAIN_001  분위기 최고! 2층 창문이 넓어서 공기가 통하는 느낌이에요. 조명도 멋지고 음료와 ...   \n",
       "2  TRAIN_002  일단, 장사가 잘 되길 바라는 마음에서 별 다섯 개 드립니다. 간도 딱 맞았고, 저...   \n",
       "3  TRAIN_003  1편의 독특함 때문에 살짝 뒤로 밀린 느낌이 있지만, 여전히 재미있어요. 게임 시스...   \n",
       "4  TRAIN_004  빵점 주고 싶은걸 간신히 참았다...이런건 사상 유래가 없는,조지 루카스 영감의 스...   \n",
       "\n",
       "                                           sentence2  \\\n",
       "0  직원들 진짜 싸가지 없어요 ㅋㅋㅋㅋ 가지 마숑  인터넷이 더 싼거 알면서도 이것저것...   \n",
       "1  분위기가 너무 좋아요! 2층 창문이 넓어서 쾌적한 느낌이에요. 조명도 아름답고 음료...   \n",
       "2  일단 장사가 잘되길 바라는 마음에서 별5개 드립니다 간도 맞았고 매운걸 좋아하는 입...   \n",
       "3  1편의 신선함에 비해 약간 빛이 바래 보이지만, 여전히 재미있게 즐길 수 있어요. ...   \n",
       "4  빵점을 주고 싶지만 참아냈습니다... 이 영화는 사상 유래가 없는 것 같아요. 조지...   \n",
       "\n",
       "                                           sentence3  \\\n",
       "0  직원들 정말 싸가지 없네요 ㅋㅋㅋㅋ 인터넷에서 더 싸게 구입할 수 있다는 걸 알면서...   \n",
       "1  분위기가 짱!! 2층 창문이 커서 탁 트여있는 느낌이에요 ㅎㅎ 조명도 예쁘고 음료랑...   \n",
       "2  일단 저는 장사가 잘되기를 바라는 마음에서 별 다섯 개를 주고 싶어요. 맛도 딱 맞...   \n",
       "3  1편의 독특함 때문에 약간의 비교가 불가피하지만, 이 게임은 여전히 흥미로워요. 시...   \n",
       "4  빵점 주고 싶을 정도로 엄청 실망했어요... 이 영화는 별들의 전쟁처럼 역사적인 작...   \n",
       "\n",
       "                                           sentence4  label  \n",
       "0  직원들의 태도가 정말 별로였어요 ㅋㅋㅋㅋ 가볼만한 가게라는 소문을 듣고 인터넷으로 ...      2  \n",
       "1  분위기가 너무 좋아요! 2층 창문이 크고 넓어서 탁 트여있는 느낌이에요. 조명도 예...      3  \n",
       "2  먼저, 칭찬과 응원의 의미로 별 다섯 개를 주고 싶습니다. 간도 딱 맞고, 저는 매...      2  \n",
       "3  1편이 워낙 참신했던 탓에 좀 묻힌 감이 있긴 하지만 재미는 여전합니다. 시스템도 ...      4  \n",
       "4  빵점을 주고 싶었는데 참았어요... 이런 영화는 전례가 없는데, 조지 루카스의 스타...      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fb1261",
   "metadata": {},
   "source": [
    "# - Kogpt2 (decoder only)\n",
    "1. github : https://github.com/skt-ai/kogpt2?utm_medium=social&utm_source=velog&utm_campaign=everyone%20ai&utm_content=kogpt2\n",
    "2. 설명1 : https://developers.kakao.com/docs/latest/ko/kogpt/common\n",
    "3. 설명2 :https://velog.io/@yeop2/AI-%EB%AA%A8%EB%8D%B8-%ED%83%90%ED%97%98%EA%B8%B0-7-%ED%95%9C%EA%B8%80-%EB%B2%84%EC%A0%84%EC%9D%98-GPT-2-KoGPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1cfd8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# 현재 GPU가 사용 가능한지 확인합니다.\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "419d27d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b1f4ec076048dc9f4b81b59da3a298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Neuer Ordner\\lib\\site-packages\\huggingface_hub\\file_download.py:123: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\황의지\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9688ed110f34086a5fe4a8031086792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41d715213c8d46cfbb6f638e9ba55bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/513M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at skt/kogpt2-base-v2 were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(51200, 768)\n",
       "  (wpe): Embedding(1024, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-11): 12 x GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2')\n",
    "# 사전 학습된 GPT-2 모델의 토크나이저, 토크나이저는 텍스트를 모델이 이해할 수 있는 형식으로 변환하는 역할\n",
    "model = AutoModel.from_pretrained('skt/kogpt2-base-v2') # 동일한 사전 학습된 GPT-2 모델의 가중치를 로드\n",
    "model.to(device) # 모델을 device로 이동"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e782493",
   "metadata": {},
   "source": [
    "# - Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b883ba",
   "metadata": {},
   "source": [
    "train_df에서 행 하나를 랜덤하게 추출하여 example로 사용(one-shot)\n",
    "\n",
    "실제 사람이 작성한 리뷰에 대해서는 '-> O'로 표시하고 그렇지 않은 리뷰에 대해서는 '-> X'로 표기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaa03cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████                                                          | 273/1100 [57:46<4:30:56, 19.66s/it]"
     ]
    }
   ],
   "source": [
    "model.eval() # 모델을 평가 모드로 설정, 학습 중에 사용되는 드롭아웃 및 배치 정규화 등의 기능이 비활성화되어 일관된 예측을 얻을 수 있음\n",
    "preds = [] # 여기에 예측결과 저장됨\n",
    "\n",
    "with torch.no_grad(): # 그레디언트 추적 비활성화, 모델을 평가할 때 불필요한 메모리 사용을 줄이고 속도를 향상\n",
    "    \n",
    "    # 각 '테스트' 케이스에 대해\n",
    "    for idx in tqdm(range(len(test_df))):\n",
    "        row = test_df.iloc[idx]\n",
    "        best_score = float('-inf') # 음의 무한대로 초기화\n",
    "        best_label = 0\n",
    "        \n",
    "        # 'train' 데이터에서 랜덤하게 문장을 가져옵니다.\n",
    "        random_row = train_df.sample(1).iloc[0]\n",
    "        random_answer = random_row['label']  #  random_row에서 랜덤하게 선택한 행의 '정답 레이블'\n",
    "        random_labels = {}\n",
    "        for i in range(1, 5):\n",
    "            random_labels[f'sentence{i}'] = 'O' if i == random_answer else 'X' #  각각의 문장에 대한 레이블은 'O' 또는 'X' 중 하나로 설정, 각 문장이 정답인지 아닌지  \n",
    "            \n",
    "        # GPT-2에게 제공할 prompt를 작성합니다.\n",
    "        example_sentence = f\"\"\"\n",
    "        주어진 문장이 사람이 작성한 것이 맞으면 O, 아니면 X를 반환하세요. \\\n",
    "\n",
    "        # 예시\n",
    "\n",
    "        문장1 : {random_row['sentence1']} -> {random_labels['sentence1']} \\\n",
    "        문장2 : {random_row['sentence2']} -> {random_labels['sentence2']} \\\n",
    "        문장3 : {random_row['sentence3']} -> {random_labels['sentence3']} \\\n",
    "        문장4 : {random_row['sentence4']} -> {random_labels['sentence4']} \\\n",
    "\n",
    "        # 문제\n",
    "        문장 :\n",
    "        \"\"\"        \n",
    "\n",
    "        # 각 문장(테스트)에 대한 확률값을 구하고, 가장 높은 확률값을 가진 문장을 선택합니다.\n",
    "        for i in range(1, 5):\n",
    "            prompt = example_sentence + \" \" + row[f\"sentence{i}\"]\n",
    "            # 예를 들어, \"주어진 문장이 사람이 작성한 것이 맞으면 O, 아니면 X를 반환하세요.\"와 \"문장 : [현재 선택한 문장]\"의 형식으로 구성\n",
    "            inputs = tokenizer(prompt, return_tensors=\"pt\")  # 토크나이징(형식변환)\n",
    "            inputs = inputs.to(device) # 입력을 사용 중인 디바이스로 이동(GPU/CPU)\n",
    "            with torch.no_grad(): # 메모리 사용 최적화\n",
    "                outputs = model(**inputs)  # 모델을 사용하여 예측을 생성\n",
    "                score = outputs[0][:, -1, :].max().item()  # 모델의 출력 중 가장 높은 값을 가져옴\n",
    "\n",
    "            if score > best_score: # best_score 음의 무한대로 초기화 됐었음\n",
    "                best_score = score\n",
    "                best_label = i\n",
    "\n",
    "        preds.append(best_label) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7a2753",
   "metadata": {},
   "source": [
    "`score = outputs[0][:, -1, :].max().item()` 이 코드는 GPT-2 모델의 출력에서 확률값을 추출하는 과정을 나타냅니다.\n",
    "\n",
    "- `outputs[0]`: GPT-2 모델의 출력 중 첫 번째 부분을 선택합니다. 일반적으로 이 부분은 모델이 예측한 토큰에 대한 확률 분포를 나타냅니다.\n",
    "\n",
    "- `[:, -1, :]`: 선택한 출력을 텐서의 슬라이싱(slice) 연산을 사용하여 조작합니다. 여기서 `[:, -1, :]`는 다음과 같이 해석됩니다:\n",
    "    - `[:, ...]`: 모든 차원의 모든 요소를 선택합니다.\n",
    "    - `-1`: 마지막 차원 (토큰의 차원)에서 마지막 요소를 선택합니다. 이것은 모델의 예측 중에서 마지막 토큰에 대한 정보를 가져옵니다.\n",
    "    - `[:]`: 선택된 차원에서 모든 요소를 선택합니다.\n",
    "\n",
    "- `.max().item()`: 선택된 확률 분포에서 가장 높은 확률값을 추출합니다. 이렇게 하면 모델이 예측한 다음 토큰 중에서 확률값이 가장 높은 토큰의 확률값을 얻게 됩니다.\n",
    "\n",
    "따라서 `score` 변수에는 현재 선택한 문장이 다음 토큰을 예측할 때의 가장 높은 확률값이 저장됩니다. 이 확률값은 모델이 현재 문장을 얼마나 확신하고 있는지를 나타냅니다. 확률값이 더 높을수록 모델은 해당 문장을 예측에 사용할 가능성이 더 큽니다. 코드는 이러한 확률값을 기록하고, 가장 높은 확률값을 가진 문장을 선택하여 최종 예측을 수행하는 데 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d343a8",
   "metadata": {},
   "source": [
    "# - Post-processing\n",
    "본 대회에서는 각 케이스에 대한 예측값을 두 개 제출할 수 있기 때문에 나머지 하나를 채워줍니다.\n",
    "\n",
    "베이스라인에서는 1,2,3,4 중에서 4를 예시로 사용했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad83179",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [str(pred) + '4' for pred in preds]\n",
    "preds[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c2c4b9",
   "metadata": {},
   "source": [
    "# - submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0972f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit['label'] = preds\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e92a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./baseline_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
